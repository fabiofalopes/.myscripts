# Vision: Smart Cache & Incremental Analysis System (V3.0)

**Status**: ğŸ“‹ PLANNING - Requirements & Architecture Design  
**Priority**: HIGH - Foundation for scalable bulk processing  
**Created**: 2025-12-09  
**Context**: After implementing V2.1 rate limiting + multi-model fallback

---

## ğŸ¯ The Core Problem

**Current Behavior** (V2.1):
```bash
./yt "VIDEO_URL"  # Run 1
# Creates: 2005-04-24_me_at_the_zoo.md

./yt "VIDEO_URL"  # Run 2 (same video)
# Creates: 2005-04-24_me_at_the_zoo (2).md  âŒ DUPLICATE!

./yt "VIDEO_URL"  # Run 3
# Creates: 2005-04-24_me_at_the_zoo (3).md  âŒ MORE DUPES!
```

**Result**: 41 files in vault, with 8 copies of same video!

**Problems**:
1. âŒ **Wasted API quota** - Re-analyzing same video multiple times
2. âŒ **Polluted vault** - Duplicate notes everywhere
3. âŒ **No incremental updates** - Can't add more patterns to existing note
4. âŒ **No bulk processing** - Can't efficiently process 100s of videos
5. âŒ **No database foundation** - Can't build vector store or knowledge graph

---

## ğŸŒŸ The Vision

### Smart Processing Modes

```
VIDEO_URL â†’ Check if exists
  â†“
  Does note exist? (by video_id)
  â†“
  NO â†’ Run full analysis (Phase 1 + 2)
  â†“
  YES â†’ Smart Update Decision
    â†“
    â”œâ”€â”€ Default: Skip (already analyzed)
    â”œâ”€â”€ --update: Update metadata only (cheap)
    â”œâ”€â”€ --append: Add new patterns (Phase 3+)
    â””â”€â”€ --force: Re-run everything (testing)
```

### Usage Examples

```bash
# SCENARIO 1: First time processing
./yt "VIDEO_URL"
# âœ… Creates new note with 5 patterns (quick mode)
# ğŸ’¾ Saves metadata: video_id, patterns_run, last_updated

# SCENARIO 2: Run again (default behavior)
./yt "VIDEO_URL"
# â­ï¸  SKIPPED: Note exists for jNQXAC9IVRw
# ğŸ’¡ Use --update to refresh or --append to add patterns

# SCENARIO 3: Add more patterns to existing note
./yt --append --patterns extract_questions extract_ideas "VIDEO_URL"
# ğŸ“ APPENDING: Adding 2 new patterns to existing note
# âœ… Added sections: AI Analysis - extract_questions, extract_ideas

# SCENARIO 4: Update metadata (video info changed)
./yt --update "VIDEO_URL"
# ğŸ”„ UPDATING: Refreshing metadata (views, likes, description)
# â±ï¸  Fast: 5s (no AI analysis, just metadata)

# SCENARIO 5: Force re-analysis (testing/debugging)
./yt --force "VIDEO_URL"
# ğŸ”¥ FORCE: Re-running full analysis
# âš ï¸  Will replace existing note

# SCENARIO 6: Bulk processing (future)
./yt --bulk playlist.txt
# ğŸ“š BULK: Processing 100 videos
# â­ï¸  Skipped: 45 (already exist)
# ğŸ†• New: 55 (will process)
# â±ï¸  Estimated: 45 min (1 min per new video)
```

---

## ğŸ—ï¸ Architecture Design

### Phase Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTRY POINT: yt "VIDEO_URL"                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 0: CACHE CHECK (NEW!)                                â”‚
â”‚ â€¢ Extract video_id from URL                                 â”‚
â”‚ â€¢ Check if note exists: $OBSVAULT/youtube/cache/{id}.json  â”‚
â”‚ â€¢ Load existing analysis state                              â”‚
â”‚ Decision:                                                    â”‚
â”‚   - No cache â†’ Proceed to Phase 1                          â”‚
â”‚   - Cache exists + no flags â†’ SKIP (return existing path)  â”‚
â”‚   - Cache exists + --update â†’ Update metadata only         â”‚
â”‚   - Cache exists + --append â†’ Jump to Phase 3+             â”‚
â”‚   - Cache exists + --force â†’ Delete cache, full re-run     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: METADATA EXTRACTION (Existing)                    â”‚
â”‚ â€¢ Extract video info (title, duration, description)        â”‚
â”‚ â€¢ Extract transcript                                        â”‚
â”‚ â€¢ Extract global context (summary, theme, topics)          â”‚
â”‚ â€¢ ğŸ’¾ Save to cache: video_metadata.json                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: CORE ANALYSIS (Existing)                          â”‚
â”‚ â€¢ Chunk transcript                                          â”‚
â”‚ â€¢ Run core patterns (5-15 patterns based on mode)          â”‚
â”‚ â€¢ Combine outputs                                           â”‚
â”‚ â€¢ ğŸ’¾ Save to cache: patterns_run.json                      â”‚
â”‚ â€¢ ğŸ“ Create initial note                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3+: INCREMENTAL ANALYSIS (NEW!)                      â”‚
â”‚ â€¢ Load existing note                                        â”‚
â”‚ â€¢ Run additional patterns (user specified)                 â”‚
â”‚ â€¢ Append new sections to note                              â”‚
â”‚ â€¢ ğŸ’¾ Update cache: append pattern names                    â”‚
â”‚ â€¢ âš ï¸  Token intensive (chunks Ã— new patterns)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: Structured Data Ready for Post-Processing          â”‚
â”‚ â€¢ Markdown note (human readable)                           â”‚
â”‚ â€¢ JSON cache (machine readable)                            â”‚
â”‚ â€¢ Ready for: Vector DB, Knowledge Graph, RAG, etc.         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Cache Structure

### File Organization

```
$OBSVAULT/youtube/
â”œâ”€â”€ .cache/                    # Cache directory (NEW!)
â”‚   â”œâ”€â”€ jNQXAC9IVRw.json      # Per-video cache file
â”‚   â”œâ”€â”€ ugvHCXCOmm4.json
â”‚   â””â”€â”€ index.json             # Quick lookup index
â”‚
â”œâ”€â”€ 2005-04-24_me_at_the_zoo.md    # Markdown note
â””â”€â”€ 2024-11-11_dario_amodei_...md
```

### Cache File Format (`{video_id}.json`)

```json
{
  "video_id": "jNQXAC9IVRw",
  "video_url": "https://www.youtube.com/watch?v=jNQXAC9IVRw",
  "title": "Me at the zoo",
  "upload_date": "2005-04-24",
  "duration_seconds": 19,
  "transcript_word_count": 39,
  
  "processing_history": [
    {
      "timestamp": "2025-12-09T10:15:30Z",
      "mode": "quick",
      "model": "llama-4-scout",
      "patterns_run": [
        "extract_wisdom",
        "youtube_summary",
        "extract_insights",
        "extract_patterns",
        "extract_main_idea"
      ],
      "chunks_created": 1,
      "total_api_calls": 8,
      "total_tokens_used": 15000,
      "processing_time_seconds": 9.8,
      "success": true
    },
    {
      "timestamp": "2025-12-09T14:22:15Z",
      "mode": "append",
      "patterns_appended": [
        "extract_questions",
        "extract_ideas"
      ],
      "api_calls": 2,
      "tokens_used": 3000,
      "processing_time_seconds": 4.2,
      "success": true
    }
  ],
  
  "current_state": {
    "markdown_path": "~/Documents/obsidian_vault/youtube/2005-04-24_me_at_the_zoo.md",
    "last_updated": "2025-12-09T14:22:15Z",
    "all_patterns_run": [
      "extract_wisdom",
      "youtube_summary",
      "extract_insights",
      "extract_patterns",
      "extract_main_idea",
      "extract_questions",
      "extract_ideas"
    ],
    "total_sections": 9,
    "analysis_complete": false,  // User can keep adding
    "phase1_metadata": { /* cached global context */ },
    "chunks": [ /* cached chunk info */ ]
  },
  
  "statistics": {
    "total_runs": 2,
    "total_tokens_used": 18000,
    "total_time_seconds": 14.0,
    "estimated_cost": "$0.00"  // Free tier
  }
}
```

### Index File (`.cache/index.json`)

Fast lookup without reading all cache files:

```json
{
  "version": "3.0",
  "last_updated": "2025-12-09T14:22:15Z",
  "videos": {
    "jNQXAC9IVRw": {
      "title": "Me at the zoo",
      "markdown_path": "2005-04-24_me_at_the_zoo.md",
      "last_processed": "2025-12-09T14:22:15Z",
      "patterns_count": 7
    },
    "ugvHCXCOmm4": {
      "title": "Dario Amodei: Anthropic CEO...",
      "markdown_path": "2024-11-11_dario_amodei_...",
      "last_processed": "2025-12-09T12:30:00Z",
      "patterns_count": 5
    }
  },
  "statistics": {
    "total_videos": 2,
    "total_tokens_used": 450000,
    "total_notes_created": 2
  }
}
```

---

## ğŸ”§ Implementation Requirements

### REQ-1: Cache Manager Module (NEW)

**File**: `lib/cache_manager.py`

**Responsibilities**:
- Check if video already processed (by video_id)
- Load existing cache data
- Save/update cache after processing
- Manage cache index for fast lookups
- Handle cache invalidation

**Key Functions**:
```python
class CacheManager:
    def video_exists(video_id: str) -> bool
    def get_cache(video_id: str) -> CacheData | None
    def save_cache(video_id: str, data: CacheData) -> None
    def update_cache(video_id: str, updates: dict) -> None
    def get_patterns_run(video_id: str) -> List[str]
    def append_patterns(video_id: str, new_patterns: List[str]) -> None
    def invalidate_cache(video_id: str) -> None
```

### REQ-2: Update CLI with New Flags

**File**: `yt`

**New Flags**:
```bash
--skip-existing     # Default: skip if note exists (NEW DEFAULT!)
--update            # Update metadata only (fast)
--append            # Add patterns to existing note
--force             # Force re-analysis (ignore cache)
--list-processed    # Show all processed videos
--bulk FILE         # Bulk process from file (future)
```

**New Output**:
```bash
$ ./yt "VIDEO_URL"
â­ï¸  SKIPPED: Note already exists for jNQXAC9IVRw
   ğŸ“„ Existing: 2005-04-24_me_at_the_zoo.md
   ğŸ“Š Patterns: 7 (extract_wisdom, youtube_summary, ...)
   ğŸ’¡ Tip: Use --append to add more patterns

$ ./yt --append --patterns extract_questions "VIDEO_URL"
ğŸ“ APPENDING to existing note: 2005-04-24_me_at_the_zoo.md
   ğŸ†• Adding pattern: extract_questions
   â±ï¸  Processing 1 pattern Ã— 1 chunk...
âœ… Appended 1 new section to note
```

### REQ-3: Incremental Note Writer (NEW)

**File**: `lib/incremental_writer.py`

**Responsibilities**:
- Load existing markdown note
- Parse current structure
- Append new pattern sections
- Preserve existing content
- Update front matter (add new patterns to list)

**Key Functions**:
```python
class IncrementalWriter:
    def load_note(path: Path) -> Note
    def append_section(note: Note, section: Section) -> None
    def update_frontmatter(note: Note, metadata: dict) -> None
    def save_note(note: Note) -> None
```

### REQ-4: Bulk Processing (FUTURE)

**File**: `lib/bulk_processor.py`

**Workflow**:
```python
def process_bulk(video_urls: List[str], mode: str):
    # Check cache for all URLs
    existing = [url for url in video_urls if cache.exists(url)]
    new = [url for url in video_urls if not cache.exists(url)]
    
    print(f"â­ï¸  Skipped: {len(existing)} (already exist)")
    print(f"ğŸ†• New: {len(new)} (will process)")
    
    # Process only new videos
    for url in new:
        process_video(url, mode)
```

---

## ğŸ“ˆ Performance & Cost Analysis

### Current (V2.1) - No Cache
```
Process video:      50 API calls, 400K tokens, 3 min
Run again:          50 API calls, 400K tokens, 3 min  âŒ WASTED
10 re-runs:         500 calls, 4M tokens, 30 min      âŒ TERRIBLE
```

### With Cache (V3.0)
```
First run:          50 API calls, 400K tokens, 3 min
Run again:          0 calls, 0 tokens, 0.1s            âœ… INSTANT
Update metadata:    0 calls, 0 tokens, 5s              âœ… CHEAP
Append 2 patterns:  20 calls, 160K tokens, 1 min      âœ… INCREMENTAL
```

### Bulk Processing Example
```
100 video playlist:
  - 60 already processed â†’ Skip (instant)
  - 40 new videos â†’ Process (~40 min)
  
Without cache: 100 videos Ã— 3 min = 5 hours
With cache: 40 videos Ã— 1 min = 40 min (7.5x faster!)
```

---

## ğŸ¯ Future Vision: Post-Processing Pipeline

### Phase 4: Database Integration (V3.1+)

```
Markdown Notes (.md)
  â†“
Extract structured data
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector Database (Embeddings)        â”‚
â”‚ â€¢ Semantic search across videos     â”‚
â”‚ â€¢ "Find videos about AI safety"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Knowledge Graph (Entities/Relations)â”‚
â”‚ â€¢ Person â†’ Works at â†’ Company      â”‚
â”‚ â€¢ Video â†’ Mentions â†’ Concept       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG System (Question Answering)     â”‚
â”‚ Q: "What did Dario say about AGI?" â”‚
â”‚ A: [context from relevant videos]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Use Cases Enabled

1. **Semantic Search**
   - "Find all videos mentioning transformers architecture"
   - "Videos by Andrew Ng about deep learning"

2. **Knowledge Extraction**
   - Build knowledge graph of AI researchers and their work
   - Track evolution of concepts over time

3. **Content Discovery**
   - "Recommend videos similar to this one"
   - "What haven't I watched on this topic?"

4. **Synthesis**
   - "Summarize what 10 experts say about AI safety"
   - "Compare perspectives from different channels"

---

## ğŸš§ Development Phases

### Phase 3.0: Smart Cache (HIGH PRIORITY)
**Goal**: Eliminate duplicates, enable incremental updates  
**Time**: 2-3 days  
**Complexity**: Medium

**Tasks**:
- [ ] Implement CacheManager class
- [ ] Add cache check to main flow
- [ ] Implement --skip-existing (new default)
- [ ] Add --update flag (metadata refresh)
- [ ] Add --append flag (incremental patterns)
- [ ] Add --force flag (ignore cache)
- [ ] Create cache file format
- [ ] Build cache index
- [ ] Test with existing notes
- [ ] Migration: scan existing notes â†’ populate cache

### Phase 3.1: Bulk Processing (MEDIUM PRIORITY)
**Goal**: Process playlists efficiently  
**Time**: 2-3 days  
**Complexity**: Medium

**Tasks**:
- [ ] Implement BulkProcessor class
- [ ] Add --bulk flag
- [ ] Parse playlist URLs
- [ ] Parallel processing (optional)
- [ ] Progress reporting
- [ ] Error recovery
- [ ] Summary statistics

### Phase 3.2: Database Integration (FUTURE)
**Goal**: Enable advanced queries and knowledge extraction  
**Time**: 1-2 weeks  
**Complexity**: High

**Tasks**:
- [ ] Choose vector DB (Chroma, Weaviate, Qdrant)
- [ ] Implement embeddings pipeline
- [ ] Knowledge graph design
- [ ] Entity extraction
- [ ] Relation extraction
- [ ] RAG system design
- [ ] Query interface

---

## ğŸ“ Key Design Principles

1. **Cache by video_id**: Unique identifier, not filename
2. **Immutable history**: Never delete processing_history, only append
3. **Idempotent operations**: Running twice should be safe
4. **Graceful degradation**: If cache corrupt, re-process
5. **User control**: Explicit flags for different behaviors
6. **Transparency**: Show what's being skipped/updated
7. **Machine-readable**: JSON cache for future automation

---

## ğŸ“ Success Criteria

**V3.0 Definition of Done**:
- âœ… No duplicate notes created
- âœ… Default behavior: skip existing
- âœ… Can append patterns without full re-run
- âœ… Can update metadata cheaply
- âœ… Cache survives restarts
- âœ… Migration works for existing notes
- âœ… Comprehensive cache documentation

**Metrics**:
- Duplicate creation: 100% â†’ 0%
- Re-processing waste: 100% â†’ 0%
- Incremental update: N/A â†’ 5-10s per pattern
- Bulk processing: N/A â†’ 60+ videos/hour

---

## ğŸš€ Why This Matters

**Short Term**:
- Stop wasting API quota on duplicates
- Enable testing without guilt
- Clean Obsidian vault

**Medium Term**:
- Process entire channels efficiently
- Build personal knowledge base
- Track video updates over time

**Long Term**:
- Foundation for vector DB
- Knowledge graph construction
- Advanced AI-powered search
- Multi-video synthesis
- Research assistant capabilities

**This transforms the tool from "process one video" to "build a knowledge system"** ğŸ¯

