## Summary

I've created two powerful, complementary prompts:
### 1. **`transcription-terminology-analyzer.md`** (NEW)
- Analyzes raw transcriptions to detect mistranscribed technical terms
- Uses context and pattern recognition with high certainty thresholds
- Generates structured word lists for the refinement prompt
- Conservative approach—only flags terms with 80%+ confidence
- Handles: libraries, frameworks, acronyms, proper nouns, domain jargon
- Outputs in YAML or simple list format for easy integration

### 2. **`transcription-refinement-prompt-v2.md`** (UPDATED)
- Enhanced to work seamlessly with the analyzer's word list output
- Applies validated corrections with confidence
- Focuses on formatting and basic syntax while preserving content
- Clear priority system: word list → formatting → syntax
- Maintains the ultra-conservative approach to content preservation

### The Workflow:
```
Raw Transcription 
    ↓
Terminology Analyzer → Word List (validated terms)
    ↓
Refinement Prompt (transcription + word list)
    ↓
Clean, Formatted, Accurate Transcription
```

Both prompts are ready for Fabric integration and emphasize the same core principle: **preserve content integrity above all else**, while intelligently improving clarity and professionalism.


# Raw ideas - Main Transcription refinement ideas
```
we need a prompt to prune transcriptions when I mean prune is really to just correct syntax make any errors that are like of like just the way that the transcription sometimes capture some words wrong words that in context it's obvious what it is it's these things that we want to make neat plus formatting these transcriptions tend to almost like come in one sentence like if that makes sense and we kind of just want to kind of have things properly paragraphed that's all like just sentence like everything well punctuated it's like that passage we want a model to like have a prompt with such description very accurately and very like detailed to the point where it's really going to enhance the transcription but never change at all anything at all about the content it's constantly about making sure that everything is intact and if we change things it's things that are like completely obvious from context that they were just like miss transcribed and that's why in text it's weird like that plus we want to support like a word list as like a lot of things might be expressions local niche things that the user might be talking about that the transcriber regardless of who it is a model or a person might just like write it wrong just because they don really know how to write it well then we can support within this prompt a word list that can work for this effect and that can like enable the user to actually just straightforwardly input things to say okay if then it becomes obvious if putting those words and expressions in that list that like certain things that are just poorly transcribed actually meant to be the things that the user cared to actually put in and made sure that like understand it and it's kind of almost like tags where the user can just drop the words the expressions everything kind of like to work it in the sense that you you also know how to write it and form in in sense of formatting some things can be like a reference to a library for example that like you want to reference it as like you know is written like itself a library you know things of that nature is just like to keep it neat but if you notice like the prompt it's constantly about maintaining exactly what was there and never changing it and that's kind of has to be the the main the main goal if if we do if we do change and changing like the actual content of the transcription we consider it as absolutely ruining the transcription and render it worthless so this function is highly important because it's also very important not to capture into files or into the next workflows things with a lot of typos or formats with poor formatting, with just like everything with no punctuation in some cases, wrong words, things that like are completely kind of feel random in place and that's kind of the passage is literally to clean, clear, syntax, correction, punctuation, text formatting but to the bare minimum of just literally making a raw transcript looking presentable but intact in terms of content in terms of everything that is inside of it in terms of the way that the content is displayed the way that the phrases are actually like phrased like the idea here is not so much to correct and to optimize the prompt and the things that the user is saying is really to do these basic things that are completely necessary and this is it this is the full mission that we just stated to create such prompt that we can recur to several times to essentially fulfill that
```


# Raw 2 - Second prompt for word list inference and optimising preparing the first one
```
We need a better prompt because we can, for example, create a way or an agent that essentially can receive raw transcription and somehow be the agent to essentially verify and to ask questions and to make right queries, to essentially verify automatically the right word list of terminology that wasn't properly captured within the transcription and kind of like automatically make it so that this... yeah I think it's fairly explainable this way like we could just get to a point where obviously the transcription is as is just properly fermented and with no shitty out of context words because we do make sure to have a space like a literal task everything stops so this task can actually go up then validate to the words like we can read to the text several times with several probably intents and then we will like get like if words like that kind of sound like the same and are kind of like being referred to as the same what what is that and then okay that's like just some weirdly written acronym for like a library for example that the user is talking about they using whatever because then the this model will have both context and the ability to actually just ask question and say does that exist or they actually mean this thing that they also model are aware about and I think that can be very powerful the key thing that I need to unlock here is the search part of the thing but i think the prompt itself for this pretty much writes itself it maybe not even sometimes so much about search as it about more like inner inner reflection and just making sure that like this prompt also states kind of the same type of level of conservative conservative editing we don't want to edit anything at the cost of changing what the user was actually talking about but again some things will become super obvious in context that like the user actually meant and was talking about that it just got transcribed poorly and this can be a prompt very very powerful prompt that together with so together with this other prompt can really result in something super powerful like and we can really try and control also the way that this prompt outputs so that it can actually also like fit with the structured ideas that we thought for like these word list type scenarios so if you want to recapitulate this new prompt that we are creating now is supposed to be the prompt that can also read the raw transcription but it does it by trying to essentially create a word list by observing what's in the text and essentially being able to infer and we want it to do that it to do that in the moments of like absolute certainty almost where things also sometimes tend to be just straight fully obvious and all of that but it it's these cases or things that were not well pronunciated things that didn't got properly captured and kind of ended up really being a little bit weird the way that they got written and then they kind of like are obvious through this prompt and the way that we need to describe this prompt that that thing just means that other thing obviously but the the model will have to think and infer that and then we'll need to output very structured word list so that it can be passed in to this actual transcription refinement prompt that we thought so it's kind of like a thing that works together to form the whole text that gets customized for the raw transcription so it's a prompt that is static but then kind of asks for us to put in stuff like keywords and things of this nature as we also input the raw transcription to it but that's it it's just like the way that we have to really now bring into this new prompt the best of the description so that it actually is a pair powerful prompt to keep together with this one as at the end of day we kind of just will call these prompts trying to chain its outputs into each other building the prompt together with the raw transcription together with the the full thing to then in the end with this thing capture what we hope is just a perfectly formatted exactly what the user said but just like well formatted well everything kind of well placed nothing overdone because the main focus is just purely on making sure on point two i i keep repeating myself i think the ideas now are fairly obvious and straightforward and to what we need to do to both these prompts now that need to be highly effective also like this thing is gonna become part of our fabric custom prompts and fabric is like this prompt library that allows us to just like quickly from even the terminal or from the terminal to just like call in models directly with this patterns that's how they call the prompts and then like it just flows super fast and we can automate in this workflow just screams that and after we consolidate these prompts so they like in concept work will work perfectly in these workflows then we will later test them out immediately but for now the core focus is to create and to make sure that this new prompt lives to all expectations even exceeds them and that first prompt is And that first prompt is as neat as we want. I think I like it, but I will also
```